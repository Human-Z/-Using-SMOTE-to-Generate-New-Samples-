{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 从原样本中生成新样本\n",
    "- 方法：\n",
    "  利用解决样本不平衡的SMOTE算法\n",
    "- 步骤：\n",
    "  1. 从原始五个表中提取特征\n",
    "  2. 利用最终的特征总表进行SMOTE样本生成\n",
    "  3. 提取SMOTE样本中的关键信息\n",
    "  4. 从SMOTE样本关键信息中倒推新样本的浏览记录\n",
    "  5. 从SMOTE样本关键信息中倒推新样本的银行流水记录\n",
    "  6. 从原样本的用户基本信息表中随机抽取生成新样本的用户基本信息表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import time\n",
    "import datetime as dt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import math\n",
    "import random\n",
    "from random import sample\n",
    "from random import randrange\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   特征工程\n",
    "目的：提取特征，利用SMOTE算法来进行样本的生成\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 银行流水记录表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------读取数据 ------------------------------------------\n",
    "银行流水记录=pd.read_csv(\"../data/train/bank_detail_train.txt\",header=None,\n",
    "                    names=['用户标识','流水时间','交易类型','交易金额','工资收入标记'])\n",
    "银行流水记录_test=pd.read_csv(\"../data/test/bank_detail_test.txt\",header=None,\n",
    "                    names=['用户标识','流水时间','交易类型','交易金额','工资收入标记'])\n",
    "银行流水记录=pd.concat([银行流水记录,银行流水记录_test],axis=0)\n",
    "\n",
    "#将时间戳转换为真实日期形式提取月份\n",
    "银行流水记录['流水日期'] = 银行流水记录['流水时间'].apply(lambda x :time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(x)))\n",
    "银行流水记录['流水日期']=pd.to_datetime(银行流水记录['流水日期'])\n",
    "银行流水记录['month'] = 银行流水记录['流水日期'].apply(lambda x :x.strftime('%m'))\n",
    "\n",
    "#划分  收入 支出 工资\n",
    "银行流水记录_收入=银行流水记录[银行流水记录[\"交易类型\"]==0][[\"用户标识\",\"流水时间\",\"交易金额\",'month']]\n",
    "银行流水记录_支出=银行流水记录[银行流水记录[\"交易类型\"]==1][[\"用户标识\",\"流水时间\",\"交易金额\",'month']]\n",
    "银行流水记录_工资=银行流水记录[银行流水记录[\"工资收入标记\"]==1][[\"用户标识\",\"流水时间\",\"交易金额\",'month']]\n",
    "\n",
    "银行流水记录_收入=银行流水记录_收入.rename(columns={'交易金额':'收入金额'})\n",
    "银行流水记录_支出=银行流水记录_支出.rename(columns={'交易金额':'支出金额'})\n",
    "银行流水记录_工资=银行流水记录_工资.rename(columns={'交易金额':'工资金额'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------总体特征提取----------\n",
    "gb1=银行流水记录_收入.groupby([\"用户标识\"],as_index=False)#收入统计\n",
    "gb2=银行流水记录_支出.groupby([\"用户标识\"],as_index=False)#支出统计\n",
    "gb3=银行流水记录_工资.groupby([\"用户标识\"],as_index=False)#工资收入统计\n",
    "x1=gb1['收入金额'].agg({'用户收入笔数' : 'count','用户收入总计':'sum','用户收入均值':'mean','用户收入标准差':'std'})\n",
    "x2=gb2['支出金额'].agg({'用户支出笔数' : 'count','用户支出总计':'sum','用户支出均值':'mean','用户支出标准差':'std'})\n",
    "x3=gb3['工资金额'].agg({'用户工资笔数' : 'count','用户工资总计':'sum','用户工资均值':'mean','用户工资标准差':'std'})\n",
    "\n",
    "print(len(x1),len(x2),len(x3))\n",
    "feature=pd.merge(x1, x2,how='outer', on = \"用户标识\")\n",
    "feature=pd.merge(feature, x3,how='outer', on = \"用户标识\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#———————————————收入 month维度下的特征提取---------------------\n",
    "d=银行流水记录_收入\n",
    "\n",
    "#-----month维度下的特征提取\n",
    "#sum\n",
    "收入金额_sum =d['收入金额'].groupby([d['用户标识'],d['month']]).sum()\n",
    "收入金额_sum=pd.DataFrame(收入金额_sum.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 收入金额_sum.columns:\n",
    "    name_dic[str(i)]='收入金额_sum_month_'+str(i)\n",
    "收入金额_sum=收入金额_sum.rename(columns=name_dic)\n",
    "\n",
    "#mean\n",
    "收入金额_means =d['收入金额'].groupby([d['用户标识'],d['month']]).mean()\n",
    "收入金额_means=pd.DataFrame(收入金额_means.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 收入金额_means.columns:\n",
    "    name_dic[str(i)]='收入金额_mean_month_'+str(i)\n",
    "收入金额_means=收入金额_means.rename(columns=name_dic)\n",
    "\n",
    "#std\n",
    "收入金额_std =d['收入金额'].groupby([d['用户标识'],d['month']]).std()\n",
    "收入金额_std=pd.DataFrame(收入金额_std.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 收入金额_std.columns:\n",
    "    name_dic[str(i)]='收入金额_std_month_'+str(i)\n",
    "收入金额_std=收入金额_std.rename(columns=name_dic)\n",
    "#max\n",
    "收入金额_max =d['收入金额'].groupby([d['用户标识'],d['month']]).max()\n",
    "收入金额_max=pd.DataFrame(收入金额_max.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 收入金额_max.columns:\n",
    "    name_dic[str(i)]='收入金额_max_month_'+str(i)\n",
    "收入金额_max=收入金额_max.rename(columns=name_dic)\n",
    "#min\n",
    "收入金额_min =d['收入金额'].groupby([d['用户标识'],d['month']]).min()\n",
    "收入金额_min=pd.DataFrame(收入金额_min.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 收入金额_min.columns:\n",
    "    name_dic[str(i)]='收入金额_min_month_'+str(i)\n",
    "收入金额_min=收入金额_min.rename(columns=name_dic)\n",
    "\n",
    "银行流水收入_month=pd.merge(收入金额_sum,收入金额_means,how=\"inner\",on=\"用户标识\")\n",
    "银行流水收入_month=pd.merge(银行流水收入_month,收入金额_max,how=\"inner\",on=\"用户标识\")\n",
    "银行流水收入_month=pd.merge(银行流水收入_month,收入金额_min,how=\"inner\",on=\"用户标识\")\n",
    "银行流水收入_month=pd.merge(银行流水收入_month,收入金额_std,how=\"inner\",on=\"用户标识\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------支出  month维度下的特征提取---------------------------\n",
    "d=银行流水记录_支出\n",
    "\n",
    "#sum\n",
    "支出金额_sum =d['支出金额'].groupby([d['用户标识'],d['month']]).sum()\n",
    "支出金额_sum=pd.DataFrame(支出金额_sum.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 支出金额_sum.columns:\n",
    "    name_dic[str(i)]='支出金额_sum_month_'+str(i)\n",
    "支出金额_sum=支出金额_sum.rename(columns=name_dic)\n",
    "\n",
    "#mean\n",
    "支出金额_mean =d['支出金额'].groupby([d['用户标识'],d['month']]).mean()\n",
    "支出金额_means=pd.DataFrame(支出金额_mean.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 支出金额_means.columns:\n",
    "    name_dic[str(i)]='支出金额_mean_month_'+str(i)\n",
    "支出金额_means=支出金额_means.rename(columns=name_dic)\n",
    "\n",
    "#std\n",
    "支出金额_std =d['支出金额'].groupby([d['用户标识'],d['month']]).std()\n",
    "支出金额_std=pd.DataFrame(支出金额_std.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 支出金额_std.columns:\n",
    "    name_dic[str(i)]='支出金额_std_month_'+str(i)\n",
    "支出金额_std=支出金额_std.rename(columns=name_dic)\n",
    "#max\n",
    "支出金额_max =d['支出金额'].groupby([d['用户标识'],d['month']]).max()\n",
    "支出金额_max=pd.DataFrame(支出金额_max.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 支出金额_max.columns:\n",
    "    name_dic[str(i)]='支出金额_max_month_'+str(i)\n",
    "支出金额_max=支出金额_max.rename(columns=name_dic)\n",
    "#min\n",
    "支出金额_min =d['支出金额'].groupby([d['用户标识'],d['month']]).min()\n",
    "支出金额_min=pd.DataFrame(支出金额_min.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 支出金额_min.columns:\n",
    "    name_dic[str(i)]='支出金额_min_month_'+str(i)\n",
    "支出金额_min=支出金额_min.rename(columns=name_dic)\n",
    "\n",
    "银行流水支出_month=pd.merge(支出金额_sum,支出金额_means,how=\"inner\",on=\"用户标识\")\n",
    "银行流水支出_month=pd.merge(银行流水支出_month,支出金额_max,how=\"inner\",on=\"用户标识\")\n",
    "银行流水支出_month=pd.merge(银行流水支出_month,支出金额_min,how=\"inner\",on=\"用户标识\")\n",
    "银行流水支出_month=pd.merge(银行流水支出_month,支出金额_std,how=\"inner\",on=\"用户标识\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------工资 month维度下的特征提取------------------------------------\n",
    "d=银行流水记录_工资\n",
    "    \n",
    "#sum\n",
    "工资金额_sum =d['工资金额'].groupby([d['用户标识'],d['month']]).sum()\n",
    "工资金额_sum=pd.DataFrame(工资金额_sum.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 工资金额_sum.columns:\n",
    "    name_dic[str(i)]='工资金额_sum_month_'+str(i)\n",
    "工资金额_sum=工资金额_sum.rename(columns=name_dic)\n",
    "\n",
    "#mean\n",
    "工资金额_mean =d['工资金额'].groupby([d['用户标识'],d['month']]).mean()\n",
    "工资金额_mean=pd.DataFrame(工资金额_mean.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 工资金额_mean.columns:\n",
    "    name_dic[str(i)]='工资金额_mean_month_'+str(i)\n",
    "工资金额_means=工资金额_mean.rename(columns=name_dic)\n",
    "\n",
    "#std\n",
    "工资金额_std =d['工资金额'].groupby([d['用户标识'],d['month']]).std()\n",
    "工资金额_std=pd.DataFrame(工资金额_std.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 工资金额_std.columns:\n",
    "    name_dic[str(i)]='工资金额_std_month_'+str(i)\n",
    "工资金额_std=工资金额_std.rename(columns=name_dic)\n",
    "#max\n",
    "工资金额_max =d['工资金额'].groupby([d['用户标识'],d['month']]).max()\n",
    "工资金额_max=pd.DataFrame(工资金额_max.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 工资金额_max.columns:\n",
    "    name_dic[str(i)]='工资金额_max_month_'+str(i)\n",
    "工资金额_max=工资金额_max.rename(columns=name_dic)\n",
    "#min\n",
    "工资金额_min =d['工资金额'].groupby([d['用户标识'],d['month']]).min()\n",
    "工资金额_min=pd.DataFrame(工资金额_min.unstack())\n",
    "\n",
    "name_dic={}\n",
    "for i in 工资金额_min.columns:\n",
    "    name_dic[str(i)]='工资金额_min_month_'+str(i)\n",
    "工资金额_min=工资金额_min.rename(columns=name_dic)\n",
    "\n",
    "银行流水工资_month=pd.merge(工资金额_sum,工资金额_means,how=\"inner\",on=\"用户标识\")\n",
    "银行流水工资_month=pd.merge(银行流水工资_month,工资金额_max,how=\"inner\",on=\"用户标识\")\n",
    "银行流水工资_month=pd.merge(银行流水工资_month,工资金额_min,how=\"inner\",on=\"用户标识\")\n",
    "银行流水工资_month=pd.merge(银行流水工资_month,工资金额_std,how=\"inner\",on=\"用户标识\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_feature=pd.merge(feature,银行流水收入_month,how='outer',on='用户标识')\n",
    "bank_feature=pd.merge(bank_feature,银行流水支出_month,how=\"outer\",on=\"用户标识\")\n",
    "bank_feature=pd.merge(bank_feature,银行流水工资_month,how=\"outer\",on=\"用户标识\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   信用卡账单记录表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取文件\n",
    "bill= pd.read_csv(\"bill_detail.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=bill\n",
    "###补充特征，增加整体的各种统计信息sum count max min mean std var等\n",
    "gb=d.loc[:,['用户标识', '上期账单金额', '上期还款金额','信用卡额度','本期账单余额','本期账单最低还款额',\n",
    "                                  '消费笔数','本期账单金额','调整金额','循环利息','可用余额','预借现金额度','还款状态']].groupby([\"用户标识\"],as_index=False)\n",
    "\n",
    "整体账单sum=gb.sum()\n",
    "整体账单sum.columns = ['用户标识', '整体上期账单金额sum', '整体上期还款金额sum','整体信用卡额度sum','整体本期账单余额sum',\n",
    "                     '整体本期账单最低还款额sum','整体消费笔数sum','整体本期账单金额sum','整体调整金额sum','整体循环利息sum',\n",
    "                     '整体可用余额sum','整体预借现金额度sum','整体还款状态sum']\n",
    "feature=整体账单sum\n",
    "feature['整体上期还款金额sum与整体上期账单金额sum差值']=feature['整体上期还款金额sum']-feature['整体上期账单金额sum']\n",
    "feature['整体信用卡额度sum与整体本期账单余额sum差值']=feature['整体信用卡额度sum']-feature['整体本期账单余额sum']\n",
    "feature['整体可用余额sum与整体预借现金额度sum差值']=feature['整体可用余额sum']-feature['整体预借现金额度sum']\n",
    "feature['整体本期账单最低还款额sum与整体循环利息sum之和']=feature['整体本期账单最低还款额sum']+feature['整体循环利息sum']\n",
    "\n",
    "\n",
    "整体账单max=gb.max()\n",
    "整体账单max.columns = ['用户标识', '整体上期账单金额max', '整体上期还款金额max','整体信用卡额度max','整体本期账单余额max',\n",
    "                     '整体本期账单最低还款额max','整体消费笔数max','整体本期账单金额max','整体调整金额max','整体循环利息max',\n",
    "                     '整体可用余额max','整体预借现金额度max','整体还款状态max']\n",
    "feature=pd.merge(feature, 整体账单max,how='left', on = \"用户标识\")\n",
    "feature['整体上期还款金额max与整体上期账单金额max差值']=feature['整体上期还款金额max']-feature['整体上期账单金额max']\n",
    "feature['整体信用卡额度max与整体本期账单余额max差值']=feature['整体信用卡额度max']-feature['整体本期账单余额max']\n",
    "feature['整体可用余额max与整体预借现金额度max差值']=feature['整体可用余额max']-feature['整体预借现金额度max']\n",
    "feature['整体本期账单最低还款额max与整体循环利息max之和']=feature['整体本期账单最低还款额max']+feature['整体循环利息max']\n",
    "\n",
    "整体账单min=gb.min()\n",
    "整体账单min.columns = ['用户标识', '整体上期账单金额min', '整体上期还款金额min','整体信用卡额度min','整体本期账单余额min',\n",
    "                     '整体本期账单最低还款额min','整体消费笔数min','整体本期账单金额min','整体调整金额min','整体循环利息min',\n",
    "                     '整体可用余额min','整体预借现金额度min','整体还款状态min']\n",
    "feature=pd.merge(feature, 整体账单min,how='left', on = \"用户标识\")\n",
    "feature['整体上期还款金额min与整体上期账单金额min差值']=feature['整体上期还款金额min']-feature['整体上期账单金额min']\n",
    "feature['整体信用卡额度min与整体本期账单余额min差值']=feature['整体信用卡额度min']-feature['整体本期账单余额min']\n",
    "feature['整体可用余额min与整体预借现金额度min差值']=feature['整体可用余额min']-feature['整体预借现金额度min']\n",
    "feature['整体本期账单最低还款额min与整体循环利息min之和']=feature['整体本期账单最低还款额min']+feature['整体循环利息min']\n",
    "\n",
    "整体账单mean=gb.mean()\n",
    "整体账单mean.columns = ['用户标识', '整体上期账单金额mean', '整体上期还款金额mean','整体信用卡额度mean','整体本期账单余额mean',\n",
    "                     '整体本期账单最低还款额mean','整体消费笔数mean','整体本期账单金额mean','整体调整金额mean','整体循环利息mean',\n",
    "                     '整体可用余额mean','整体预借现金额度mean','整体还款状态mean']\n",
    "feature=pd.merge(feature, 整体账单mean,how='left', on = \"用户标识\")\n",
    "feature['整体上期还款金额mean与整体上期账单金额mean差值']=feature['整体上期还款金额mean']-feature['整体上期账单金额mean']\n",
    "feature['整体信用卡额度mean与整体本期账单余额mean差值']=feature['整体信用卡额度mean']-feature['整体本期账单余额mean']\n",
    "feature['整体可用余额mean与整体预借现金额度mean差值']=feature['整体可用余额mean']-feature['整体预借现金额度mean']\n",
    "feature['整体本期账单最低还款额mean与整体循环利息mean之和']=feature['整体本期账单最低还款额mean']+feature['整体循环利息mean']\n",
    "\n",
    "整体账单median=gb.median()\n",
    "整体账单median.columns = ['用户标识', '整体上期账单金额median', '整体上期还款金额median','整体信用卡额度median','整体本期账单余额median',\n",
    "                  '整体本期账单最低还款额median','整体消费笔数median','整体本期账单金额median','整体调整金额median',\n",
    "                  '整体循环利息median','整体可用余额median','整体预借现金额度median','整体还款状态median']\n",
    "feature=pd.merge(feature, 整体账单median,how='left', on = \"用户标识\")\n",
    "feature['整体上期还款金额median与整体上期账单金额median差值']=feature['整体上期还款金额median']-feature['整体上期账单金额median']\n",
    "feature['整体信用卡额度median与整体本期账单余额median差值']=feature['整体信用卡额度median']-feature['整体本期账单余额median']\n",
    "feature['整体可用余额median与整体预借现金额度median差值']=feature['整体可用余额median']-feature['整体预借现金额度median']\n",
    "feature['整体本期账单最低还款额median与整体循环利息median之和']=feature['整体本期账单最低还款额median']+feature['整体循环利息median']\n",
    "\n",
    "整体账单std=gb.std()\n",
    "整体账单std.columns = ['用户标识', '整体上期账单金额std', '整体上期还款金额std','整体信用卡额度std','整体本期账单余额std',\n",
    "                     '整体本期账单最低还款额std','整体消费笔数std','整体本期账单金额std','整体调整金额std','整体循环利息std',\n",
    "                     '整体可用余额std','整体预借现金额度std','整体还款状态std']\n",
    "feature=pd.merge(feature, 整体账单std,how='left', on = \"用户标识\")\n",
    "feature['整体上期还款金额std与整体上期账单金额std差值']=feature['整体上期还款金额std']-feature['整体上期账单金额std']\n",
    "feature['整体信用卡额度std与整体本期账单余额std差值']=feature['整体信用卡额度std']-feature['整体本期账单余额std']\n",
    "feature['整体可用余额std与整体预借现金额度std差值']=feature['整体可用余额std']-feature['整体预借现金额度std']\n",
    "feature['整体本期账单最低还款额std与整体循环利息std之和']=feature['整体本期账单最低还款额std']+feature['整体循环利息std']\n",
    "\n",
    "整体账单var=gb.var()\n",
    "整体账单var.columns = ['用户标识', '整体上期账单金额var', '整体上期还款金额var','整体信用卡额度var','整体本期账单余额var',\n",
    "                     '整体本期账单最低还款额var','整体消费笔数var','整体本期账单金额var','整体调整金额var','整体循环利息var',\n",
    "                     '整体可用余额var','整体预借现金额度var','整体还款状态var']\n",
    "feature=pd.merge(feature, 整体账单var,how='left', on = \"用户标识\")\n",
    "feature['整体上期还款金额var与整体上期账单金额var差值']=feature['整体上期还款金额var']-feature['整体上期账单金额var']\n",
    "feature['整体信用卡额度var与整体本期账单余额var差值']=feature['整体信用卡额度var']-feature['整体本期账单余额var']\n",
    "feature['整体可用余额var与整体预借现金额度var差值']=feature['整体可用余额var']-feature['整体预借现金额度var']\n",
    "feature['整体本期账单最低还款额var与整体循环利息var之和']=feature['整体本期账单最低还款额var']+feature['整体循环利息var']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=d.loc[:,['用户标识','时间','银行标识','上期账单金额', '上期还款金额','信用卡额度','本期账单余额'\n",
    "              ,'本期账单最低还款额','消费笔数','本期账单金额','调整金额','循环利息','可用余额'\n",
    "              ,'预借现金额度']].groupby([\"用户标识\",\"时间\",\"银行标识\"],as_index=False).max()\n",
    "\n",
    "gb=data.loc[:,['用户标识', '上期账单金额', '上期还款金额','信用卡额度','本期账单余额','本期账单最低还款额',\n",
    "               '消费笔数','本期账单金额','调整金额','循环利息','可用余额','预借现金额度']].groupby([\"用户标识\"],as_index=False)\n",
    "\n",
    "去重后整体账单sum=gb.sum()\n",
    "去重后整体账单sum.columns = ['用户标识', '去重后整体上期账单金额sum', '去重后整体上期还款金额sum','去重后整体信用卡额度sum'\n",
    "                       ,'去重后整体本期账单余额sum','去重后整体本期账单最低还款额sum','去重后整体消费笔数sum'\n",
    "                       ,'去重后整体本期账单金额sum','去重后整体调整金额sum','去重后整体循环利息sum','去重后整体可用余额sum'\n",
    "                       ,'去重后整体预借现金额度sum']\n",
    "feature=pd.merge(feature, 去重后整体账单sum,how='left', on = \"用户标识\")\n",
    "feature['去重后整体上期还款金额sum与整体上期账单金额sum差值']=feature['去重后整体上期还款金额sum']-feature['去重后整体上期账单金额sum']\n",
    "feature['去重后整体信用卡额度sum与整体本期账单余额sum差值']=feature['去重后整体信用卡额度sum']-feature['去重后整体本期账单余额sum']\n",
    "feature['去重后整体可用余额sum与整体预借现金额度sum差值']=feature['去重后整体可用余额sum']-feature['去重后整体预借现金额度sum']\n",
    "feature['去重后整体本期账单最低还款额sum与整体循环利息sum之和']=feature['去重后整体本期账单最低还款额sum']+feature['去重后整体循环利息sum']\n",
    "\n",
    "\n",
    "去重后整体账单max=gb.max()\n",
    "去重后整体账单max.columns = ['用户标识', '去重后整体上期账单金额max', '去重后整体上期还款金额max','去重后整体信用卡额度max'\n",
    "                       ,'去重后整体本期账单余额max','去重后整体本期账单最低还款额max','去重后整体消费笔数max'\n",
    "                       ,'去重后整体本期账单金额max','去重后整体调整金额max','去重后整体循环利息max'\n",
    "                       ,'去重后整体可用余额max','去重后整体预借现金额度max']\n",
    "feature=pd.merge(feature, 去重后整体账单max,how='left', on = \"用户标识\")\n",
    "feature['去重后整体上期还款金额max与整体上期账单金额max差值']=feature['去重后整体上期还款金额max']-feature['去重后整体上期账单金额max']\n",
    "feature['去重后整体信用卡额度max与整体本期账单余额max差值']=feature['去重后整体信用卡额度max']-feature['去重后整体本期账单余额max']\n",
    "feature['去重后整体可用余额max与整体预借现金额度max差值']=feature['去重后整体可用余额max']-feature['去重后整体预借现金额度max']\n",
    "feature['去重后整体本期账单最低还款额max与整体循环利息max之和']=feature['去重后整体本期账单最低还款额max']+feature['去重后整体循环利息max']\n",
    "\n",
    "去重后整体账单min=gb.min()\n",
    "去重后整体账单min.columns = ['用户标识', '去重后整体上期账单金额min', '去重后整体上期还款金额min','去重后整体信用卡额度min'\n",
    "                       ,'去重后整体本期账单余额min','去重后整体本期账单最低还款额min','去重后整体消费笔数min'\n",
    "                       ,'去重后整体本期账单金额min','去重后整体调整金额min','去重后整体循环利息min'\n",
    "                       ,'去重后整体可用余额min','去重后整体预借现金额度min']\n",
    "feature=pd.merge(feature, 去重后整体账单min,how='left', on = \"用户标识\")\n",
    "feature['去重后整体上期还款金额min与整体上期账单金额min差值']=feature['去重后整体上期还款金额min']-feature['去重后整体上期账单金额min']\n",
    "feature['去重后整体信用卡额度min与整体本期账单余额min差值']=feature['去重后整体信用卡额度min']-feature['去重后整体本期账单余额min']\n",
    "feature['去重后整体可用余额min与整体预借现金额度min差值']=feature['去重后整体可用余额min']-feature['去重后整体预借现金额度min']\n",
    "feature['去重后整体本期账单最低还款额min与整体循环利息min之和']=feature['去重后整体本期账单最低还款额min']+feature['去重后整体循环利息min']\n",
    "\n",
    "去重后整体账单mean=gb.mean()\n",
    "去重后整体账单mean.columns = ['用户标识', '去重后整体上期账单金额mean', '去重后整体上期还款金额mean','去重后整体信用卡额度mean'\n",
    "                        ,'去重后整体本期账单余额mean','去重后整体本期账单最低还款额mean','去重后整体消费笔数mean'\n",
    "                        ,'去重后整体本期账单金额mean','去重后整体调整金额mean','去重后整体循环利息mean'\n",
    "                        ,'去重后整体可用余额mean','去重后整体预借现金额度mean']\n",
    "feature=pd.merge(feature, 去重后整体账单mean,how='left', on = \"用户标识\")\n",
    "feature['去重后整体上期还款金额mean与整体上期账单金额mean差值']=feature['去重后整体上期还款金额mean']-feature['去重后整体上期账单金额mean']\n",
    "feature['去重后整体信用卡额度mean与整体本期账单余额mean差值']=feature['去重后整体信用卡额度mean']-feature['去重后整体本期账单余额mean']\n",
    "feature['去重后整体可用余额mean与整体预借现金额度mean差值']=feature['去重后整体可用余额mean']-feature['去重后整体预借现金额度mean']\n",
    "feature['去重后整体本期账单最低还款额mean与整体循环利息mean之和']=feature['去重后整体本期账单最低还款额mean']+feature['去重后整体循环利息mean']\n",
    "\n",
    "\n",
    "去重后整体账单median=gb.median()\n",
    "去重后整体账单median.columns = ['用户标识', '去重后整体上期账单金额median', '去重后整体上期还款金额median'\n",
    "                          ,'去重后整体信用卡额度median','去重后整体本期账单余额median','去重后整体本期账单最低还款额median'\n",
    "                          ,'去重后整体消费笔数median','去重后整体本期账单金额median','去重后整体调整金额median'\n",
    "                          ,'去重后整体循环利息median','去重后整体可用余额median','去重后整体预借现金额度median']\n",
    "feature=pd.merge(feature, 去重后整体账单median,how='left', on = \"用户标识\")\n",
    "feature['去重后整体上期还款金额median与整体上期账单金额median差值']=feature['去重后整体上期还款金额median']-feature['去重后整体上期账单金额median']\n",
    "feature['去重后整体信用卡额度median与整体本期账单余额median差值']=feature['去重后整体信用卡额度median']-feature['去重后整体本期账单余额median']\n",
    "feature['去重后整体可用余额median与整体预借现金额度median差值']=feature['去重后整体可用余额median']-feature['去重后整体预借现金额度median']\n",
    "feature['去重后整体本期账单最低还款额median与整体循环利息median之和']=feature['去重后整体本期账单最低还款额median']+feature['去重后整体循环利息median']\n",
    "\n",
    "\n",
    "去重后整体账单std=gb.std()\n",
    "去重后整体账单std.columns = ['用户标识', '去重后整体上期账单金额std', '去重后整体上期还款金额std','去重后整体信用卡额度std'\n",
    "                       ,'去重后整体本期账单余额std','去重后整体本期账单最低还款额std','去重后整体消费笔数std'\n",
    "                       ,'去重后整体本期账单金额std','去重后整体调整金额std','去重后整体循环利息std'\n",
    "                       ,'去重后整体可用余额std','去重后整体预借现金额度std']\n",
    "feature=pd.merge(feature, 去重后整体账单std,how='left', on = \"用户标识\")\n",
    "feature['去重后整体上期还款金额std与整体上期账单金额std差值']=feature['去重后整体上期还款金额std']-feature['去重后整体上期账单金额std']\n",
    "feature['去重后整体信用卡额度std与整体本期账单余额std差值']=feature['去重后整体信用卡额度std']-feature['去重后整体本期账单余额std']\n",
    "feature['去重后整体可用余额std与整体预借现金额度std差值']=feature['去重后整体可用余额std']-feature['去重后整体预借现金额度std']\n",
    "feature['去重后整体本期账单最低还款额std与整体循环利息std之和']=feature['去重后整体本期账单最低还款额std']+feature['去重后整体循环利息std']\n",
    "\n",
    "去重后整体账单var=gb.var()\n",
    "去重后整体账单var.columns = ['用户标识', '去重后整体上期账单金额var', '去重后整体上期还款金额var','去重后整体信用卡额度var'\n",
    "                       ,'去重后整体本期账单余额var','去重后整体本期账单最低还款额var','去重后整体消费笔数var'\n",
    "                       ,'去重后整体本期账单金额var','去重后整体调整金额var','去重后整体循环利息var','去重后整体可用余额var','去重后整体预借现金额度var']\n",
    "feature=pd.merge(feature, 去重后整体账单var,how='left', on = \"用户标识\")\n",
    "feature['去重后整体上期还款金额var与整体上期账单金额var差值']=feature['去重后整体上期还款金额var']-feature['去重后整体上期账单金额var']\n",
    "feature['去重后整体信用卡额度var与整体本期账单余额var差值']=feature['去重后整体信用卡额度var']-feature['去重后整体本期账单余额var']\n",
    "feature['去重后整体可用余额var与整体预借现金额度var差值']=feature['去重后整体可用余额var']-feature['去重后整体预借现金额度var']\n",
    "feature['去重后整体本期账单最低还款额var与整体循环利息var之和']=feature['去重后整体本期账单最低还款额var']+feature['去重后整体循环利息var']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爆卡指的是本期账单余额大于信用卡额度\n",
    "d=bill\n",
    "gb=d[(d['信用卡额度']<d['本期账单余额'])].groupby([\"用户标识\"],as_index=False)\n",
    "x1=gb['时间'].apply(lambda x:np.unique(x).size)\n",
    "x=gb['时间'].agg({'爆卡次数' : 'count'})\n",
    "x['爆卡次数(去重)']=x1\n",
    "feature=pd.merge(feature, x,how='left', on = \"用户标识\")\n",
    "\n",
    "#用户持卡数\n",
    "gb=d.groupby([\"用户标识\"],as_index=False)\n",
    "x=gb['银行标识'].apply(lambda x:np.unique(x).size)\n",
    "x1=gb['银行标识'].agg({'用户银行卡账单计数' : 'count'})\n",
    "x1['用户持卡数']=x\n",
    "feature=pd.merge(feature,x1,how='left', on = \"用户标识\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去重银行卡标识后 信用卡额度与可用余额 \n",
    "data=d.loc[:,['用户标识','银行标识','信用卡额度','可用余额','本期账单余额']].groupby([\"用户标识\",\"银行标识\"],as_index=False).max()\n",
    "gb=data.loc[:,['用户标识','信用卡额度','可用余额','本期账单余额']].groupby([\"用户标识\"],as_index=False)\n",
    "去重后信用卡额度sum=gb.sum()\n",
    "去重后信用卡额度max=gb.max()\n",
    "去重后信用卡额度min=gb.min()\n",
    "去重后信用卡额度mean=gb.mean()\n",
    "去重后信用卡额度std=gb.std()\n",
    "去重后信用卡额度var=gb.var()\n",
    "去重后信用卡额度sum.columns = ['用户标识','去重后整体信用卡额度sum','去重后整体可用余额sum','去重后本期账单余额sum']\n",
    "去重后信用卡额度max.columns = ['用户标识','去重后整体信用卡额度max','去重后整体可用余额max','去重后本期账单余额max']\n",
    "去重后信用卡额度min.columns = ['用户标识','去重后整体信用卡额度min','去重后整体可用余额min','去重后本期账单余额min']\n",
    "去重后信用卡额度mean.columns = ['用户标识','去重后整体信用卡额度mean','去重后整体可用余额mean','去重后本期账单余额mean']\n",
    "去重后信用卡额度std.columns = ['用户标识','去重后整体信用卡额度std','去重后整体可用余额std','去重后本期账单余额std']\n",
    "去重后信用卡额度var.columns = ['用户标识','去重后整体信用卡额度var','去重后整体可用余额var','去重后本期账单余额var']\n",
    "\n",
    "feature1=pd.merge(去重后信用卡额度sum, 去重后信用卡额度max,how='outer', on = \"用户标识\")\n",
    "feature1=pd.merge(feature1, 去重后信用卡额度min,how='left', on = \"用户标识\")\n",
    "feature1=pd.merge(feature1, 去重后信用卡额度mean,how='left', on = \"用户标识\")\n",
    "feature1=pd.merge(feature1, 去重后信用卡额度std,how='left', on = \"用户标识\")\n",
    "feature1=pd.merge(feature1, 去重后信用卡额度var,how='left', on = \"用户标识\")\n",
    "\n",
    "bill_feature=pd.merge(feature, feature1,how='left', on = \"用户标识\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  浏览数据表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "browse=pd.read_csv('../data/train/browse_history_train.txt',encoding='gb2312',header=None,names=['用户标识','浏览时间','浏览行为数据','浏览子行为编号'])\n",
    "browse_test=pd.read_csv('../data/test/browse_history_test.txt',encoding='gb2312',header=None,names=['用户标识','浏览时间','浏览行为数据','浏览子行为编号'])\n",
    "browse=pd.concat([browse,browse_test],axis=0)\n",
    "\n",
    "#将时间戳转换为标准日期  提取month week day\n",
    "browse['浏览日期'] = browse['浏览时间'].apply(lambda x :time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(x)))\n",
    "browse['浏览日期'] = pd.to_datetime(browse['浏览日期'])\n",
    "browse['month'] = browse['浏览日期'].apply(lambda x :x.strftime('%m'))\n",
    "browse['week']= browse['浏览日期'].dt.dayofweek ##输出这一天是周中的第几天，Monday=0, Sunday=6\n",
    "browse['day'] = browse['浏览日期'].apply(lambda x :x.strftime('%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#-------------------整体特征---------------------\n",
    "\n",
    "browse['month']=browse['month'].map(lambda x:int(x))\n",
    "browse['day']=browse['day'].map(lambda x:int(x))\n",
    "\n",
    "gb=browse.groupby([\"用户标识\"],as_index=False)\n",
    "x1=gb['浏览子行为编号'].agg({'浏览次数' : 'count'})\n",
    "x2=gb['浏览行为数据'].agg({'浏览行为数据sum' : 'sum','浏览行为数据max' : 'max','浏览行为数据mean' : 'mean',\n",
    "                     '浏览行为数据min' : 'min','浏览行为数据std' : 'std','浏览行为数据var' : 'var'})\n",
    "# 提取各特征出现的种数\n",
    "xx1=gb['浏览子行为编号'].apply(lambda x:np.unique(x).size)\n",
    "xx2=gb['浏览行为数据'].apply(lambda x:np.unique(x).size)\n",
    "xx3=gb['month'].apply(lambda x:np.unique(x).size)\n",
    "xx4=gb['week'].apply(lambda x:np.unique(x).size)\n",
    "xx5=gb['day'].apply(lambda x:np.unique(x).size)\n",
    "\n",
    "x2['浏览子行为编号种类']=xx1\n",
    "x2['浏览行为数据种类']=xx2\n",
    "x2['month种类']=xx3\n",
    "x2['week种类']=xx4\n",
    "x2['day种类']=xx5\n",
    "\n",
    "#各子行为编号下的记录数\n",
    "f=browse\n",
    "gf=f['浏览行为数据'].groupby([f['用户标识'],f['浏览子行为编号']]).count()\n",
    "gf=pd.DataFrame(gf.unstack())\n",
    "name=[]\n",
    "for i in range(1,12,1):\n",
    "    name.append('num_子行为编号_'+str(i))\n",
    "gf.columns=name\n",
    "\n",
    "feature=pd.merge(x1,x2,how='outer',on='用户标识')\n",
    "feature=pd.merge(feature,gf,how='outer',on='用户标识')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#--------------时间维度下特征提取------------------\n",
    "\n",
    "用户浏览行为=browse\n",
    "#month\n",
    "浏览行为数据_max =用户浏览行为['浏览行为数据'].groupby([用户浏览行为['用户标识'],用户浏览行为['month']]).max()\n",
    "浏览行为数据_max = pd.DataFrame(浏览行为数据_max.unstack())\n",
    "\n",
    "\n",
    "浏览行为数据_min =用户浏览行为['浏览行为数据'].groupby([用户浏览行为['用户标识'],用户浏览行为['month']]).min()\n",
    "浏览行为数据_min = pd.DataFrame(浏览行为数据_min.unstack())\n",
    "\n",
    "浏览行为数据_count =用户浏览行为['浏览行为数据'].groupby([用户浏览行为['用户标识'],用户浏览行为['month']]).count()\n",
    "浏览行为数据_count = pd.DataFrame(浏览行为数据_count.unstack())\n",
    "\n",
    "浏览行为_month_整体=pd.merge(浏览行为数据_max,浏览行为数据_min,how=\"left\",on=\"用户标识\")\n",
    "浏览行为_month_整体=pd.merge(浏览行为_month_整体,浏览行为数据_count,how=\"outer\",on=\"用户标识\")\n",
    "\n",
    "\n",
    "浏览行为_month_整体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browse_feature=pd.merge(feature,浏览行为_month_整体,on='用户标识',how='outer')\n",
    "browse_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   用户基本属性表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "这里考虑后期要进行样本记录的倒推，于是对于用户基本属性表不做特征处理，方便之后观察能否直接利用smote生成的记录充当用户基本属性记录\n",
    "'''\n",
    "户基本信息表=pd.read_csv(\"../data/train/user_info_train.txt\",header=None,names=['用户标识','用户性别','用户职业',\n",
    "                    '用户教育程度','用户婚姻状态','用户户口类型'])\n",
    "用户基本信息表_test=pd.read_csv(\"../Data/test/user_info_test.txt\",header=None,names=['用户标识','用户性别','用户职业',\n",
    "                    '用户教育程度','用户婚姻状态','用户户口类型'])\n",
    "user=pd.concat([用户基本信息表,用户基本信息表_test],axis=0)\n",
    "\n",
    "#dataset=用户基本信息表\n",
    "\n",
    "#label=dataset[['用户标识']]\n",
    "#dataset=dataset.drop(['用户标识'],axis=1)\n",
    "\n",
    "#dataset=pd.get_dummies(dataset,columns=['用户性别','用户职业',\n",
    "                    #'用户教育程度','用户婚姻状态','用户户口类型'])\n",
    "\n",
    "#多项式处理\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "#poly = PolynomialFeatures(degree=2,interaction_only=True)\n",
    "#dataset=poly.fit_transform(dataset)\n",
    "\n",
    "#df = pd.DataFrame(dataset.reshape(55596,301))\n",
    "#df.interpolate(axis=1).values.reshape(dataset.shape)\n",
    "\n",
    "\n",
    "#label = label.reset_index(drop= True)\n",
    "#df = df.reset_index(drop= True)\n",
    "\n",
    "#user_feature=pd.concat([label,df],axis=1)\n",
    "\n",
    "#user_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##   是否逾期表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overdue=pd.read_csv(\"../Data/train/overdue_train.txt\",header=None,\n",
    "                    names=['用户标识','样本标签'])\n",
    "overdue_test=pd.read_csv(\"../Data/test/overdue_test.csv\")\n",
    "overdue_test=overdue_test.rename(columns={'userid':'用户标识','probability':'样本标签'})\n",
    "\n",
    "overdue=pd.concat([overdue,overdue_test],axis=0)\n",
    "overdue = overdue.reset_index(drop= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------所有特征表进行合并----------\n",
    "train=pd.merge(bank_feature,browse_feature,on='用户标识',how='outer')\n",
    "train=pd.merge(train,bill_feature,on='用户标识',how='outer')\n",
    "train=pd.merge(train,user,on='用户标识',how='outer')\n",
    "train=pd.merge(train,overdue,on='用户标识',how='outer')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('prefore_trian.csv',encoding='gb2312')\n",
    "prefore_trian = train\n",
    "train['样本标签'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  SMOTE样本生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "生成正样本\n",
    "'''\n",
    "train.fillna(0,inplace=True) #用0填充缺失值\n",
    "\n",
    "smo = SMOTE(ratio={1: 16425 },random_state=42)  #生成8000条正样本\n",
    "x1,y1 = train.drop('样本标签',axis=1),train[['样本标签']]\n",
    "y1=y1.astype(int)\n",
    "x1_smo, y1_smo = smo.fit_sample(x1, y1.values.ravel())\n",
    "\n",
    "#提取生成新样本\n",
    "smo_data1=pd.DataFrame(x1_smo)\n",
    "smo_data1=smo_data1[69495:77495]\n",
    "smo_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "生成负样本\n",
    "这里采用将原来正样本修改为'负样本'，负样本修改为'正样本'，从而生成一系列'正样本'的数据。\n",
    "'''\n",
    "train2=train\n",
    "train2[['样本标签']]=train2[['样本标签']].replace(0,2)\n",
    "train2[['样本标签']]=train2[['样本标签']].replace(1,0)\n",
    "train2[['样本标签']]=train2[['样本标签']].replace(2,1)\n",
    "\n",
    "train2.fillna(0,inplace=True) #用0填充缺失值\n",
    "#生成正样本\n",
    "smo = SMOTE(ratio={1: 73070},random_state=42)  #生成负样本 12000\n",
    "x2,y2 = train2.drop('样本标签',axis=1),train2[['样本标签']]\n",
    "y2=y2.astype(int)\n",
    "x2_smo, y2_smo = smo.fit_sample(x2, y2)\n",
    "\n",
    "#提取生成新样本\n",
    "smo_data2=pd.DataFrame(x2_smo)\n",
    "smo_data2=smo_data2[69495:81495]\n",
    "smo_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正负样本合并\n",
    "prefore_train=pd.read_csv('prefore_trian.csv',encoding='gb2312')\n",
    "smo_data1['样本标签']=1\n",
    "smo_data2['样本标签']=0\n",
    "namelist=prefore_trian.columns\n",
    "smo_data1.columns=namelist  #修改列名\n",
    "smo_data2.columns=namelist\n",
    "\n",
    "smo_data=pd.concat([smo_data1,smo_data2],axis=0)  #将生成的正负样本合并\n",
    "smo_data=smo_data.sample(frac=1)    #打乱样本\n",
    "\n",
    "#给生成的新样本编号  id\n",
    "for i in range(1,len(smo_data)+1,1):\n",
    "    smo_data.iloc[i-1,0]=i+ 69495\n",
    "smo_data[['用户标识']]=smo_data['用户标识'].map(lambda x:int(x))\n",
    "smo_data_Lable=smo_data[['用户标识','样本标签']]   #保存新生成样本的Lable\n",
    "#smo_data_Lable.to_csv('smo_sample/smo_overdue.csv',encoding='gb2312',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关键特征的调整\n",
    "- SMOTE 新样本关键特征存在的问题与调整方法：\n",
    "-  金额的调整：\n",
    "   1. 原样本中收入、支出、工资总计的金额均大于4.5，所以新样本中对应金额小于4.5的替换为0\n",
    "-  缺失值的处理：\n",
    "   1. 运用SMOTE生成样本过程中，利用0进行缺失值的填充，所以生成的新样本中将0替换为NaN。\n",
    "-  逻辑关系的检验：\n",
    "   1. 新样本中存在收入支出工资总计不为0 ，但是相应笔数却为NaN的情况。\n",
    "   2. 解决方法就是找出这些记录，将相应的笔数调整为1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------提取关键特征----------------------------------------------------\n",
    "'''\n",
    "用户标识 \n",
    "bank关键信息：用户收入笔数、用户收入总计、用户支出笔数、用户支出总计、用户工资笔数、用户工资总计\n",
    "browse关键信息：浏览次数、浏览子行为编号种类、浏览行为数据种类、month种类、weeek种类、day种类\n",
    "'''\n",
    "key=['用户标识','用户收入笔数','用户收入总计','用户支出笔数','用户支出总计','用户工资笔数','用户工资总计','浏览次数','浏览子行为编号种类','浏览行为数据种类','month种类','week种类','day种类']\n",
    "key_features=smo_data[key]\n",
    "key_features[['用户标识','用户收入笔数','用户支出笔数','用户工资笔数','浏览次数','浏览子行为编号种类','浏览行为数据种类','month种类','week种类','day种类']]=key_features[['用户标识','用户收入笔数','用户支出笔数','用户工资笔数','浏览次数','浏览子行为编号种类','浏览行为数据种类','month种类','week种类','day种类']].astype(int)\n",
    "#key_features[['用户标识','用户收入笔数','用户支出笔数','用户工资笔数','浏览子行为编号种类','浏览行为数据种类','month种类','week种类','day种类']]=key_features[['用户标识','用户收入笔数','用户支出笔数','用户工资笔数','浏览子行为编号种类','浏览行为数据种类','month种类','week种类','day种类']].astype(int)\n",
    "key_features.loc[key_features['用户收入总计']<4.5,'用户收入总计']=0\n",
    "key_features.loc[key_features['用户支出总计']<4.5,'用户支出总计']=0\n",
    "key_features.loc[key_features['用户工资总计']<4.5,'用户工资总计']=0\n",
    "\n",
    "key_features=key_features.replace(0,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_key_features=key_features[['用户标识','用户收入笔数','用户收入总计','用户支出笔数','用户支出总计','用户工资笔数','用户工资总计']]\n",
    "browse_key_features=key_features[['用户标识','浏览次数','浏览子行为编号种类','浏览行为数据种类','month种类','week种类','day种类']]\n",
    "\n",
    "bank_key_features.drop_duplicates(['用户收入笔数','用户收入总计','用户支出笔数','用户支出总计','用户工资笔数','用户工资总计'],keep=False)\n",
    "\n",
    "#--------bank--------删除整行（除银行标识）为nan 的行\n",
    "bank_key_features=bank_key_features.dropna(subset=['用户收入笔数','用户收入总计','用户支出笔数','用户支出总计','用户工资笔数','用户工资总计'],how='all')\n",
    "\n",
    "#调整工资次数为0 金额不为0 的情况（支出、收入同）\n",
    "bank_key_features.loc[((bank_key_features['用户工资笔数'].isnull())&(bank_key_features['用户工资总计']>0)),'用户工资笔数']=1\n",
    "bank_key_features.loc[((bank_key_features['用户收入笔数'].isnull())&(bank_key_features['用户收入总计']>0)),'用户收入笔数']=1\n",
    "bank_key_features.loc[((bank_key_features['用户支出笔数'].isnull())&(bank_key_features['用户支出总计']>0)),'用户支出笔数']=1\n",
    "\n",
    "\n",
    "#------browse-------删除只要包含nan的行\n",
    "browse_key_features=browse_key_features.dropna(subset=['浏览次数','浏览子行为编号种类','浏览行为数据种类','month种类','week种类','day种类'],how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bank_key_features.to_csv('smo_sample/bank_key_features.csv',encoding='gb2312',index=None)\n",
    "#browse_key_features.to_csv('smo_sample/browse_key_features.csv',encoding='gb2312',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成新的浏览记录\n",
    "## 具体步骤\n",
    "- 定义关键信息：\n",
    "      ID:用户标识\n",
    "      N:浏览次数\n",
    "      n1:子行为编号种类\n",
    "      n2:浏览行为数据种类\n",
    "      n3:月份种数\n",
    "      n4:星期种数\n",
    "      n5:日期种数\n",
    "    \n",
    "- 准备各特征的取值总集：\n",
    "      子行为编号种类A，\n",
    "      浏览行为数据种类B，\n",
    "      月份Cm，\n",
    "      星期Cw，\n",
    "      日期Cd\n",
    "   \n",
    "- 生成单个id的浏览特征集合（不放回）\n",
    "   1. 从A中依照原样本分布概率抽样抽取n1个，构成A1\n",
    "   2. 从B中依照原样本分布概率抽样抽取n2个，构成B1\n",
    "   3. 从Cm中依照原样本分布概率抽样抽取n3个，构成C1\n",
    "   4. 从Cw、Cd中分别随机抽样抽取n4、n5个，构成C2、C3\n",
    "   \n",
    "- 生成浏览记录（放回）\n",
    "   1. 从A1中依概率抽取N个构成：子行为编号\n",
    "   2. 从B1中依概率取N个构成：浏览行为数据\n",
    "   3. 从C1中依概率抽取N个构成：month\n",
    "   4. 从C2、C3中分别依概率抽取N个构成：week、day\n",
    " \n",
    "- 生成所有id的记录合并在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------原数据特征准备------\n",
    "browse_key_features=pd.read_csv('smo_sample/browse_key_features.csv',encoding='gb2312')\n",
    "browse_key_features[['用户标识','浏览次数','浏览子行为编号种类','浏览行为数据种类','month种类','week种类','day种类']]=browse_key_features[['用户标识','浏览次数','浏览子行为编号种类','浏览行为数据种类','month种类','week种类','day种类']].astype(int)\n",
    "\n",
    "browse_train=pd.read_csv('../data/train/browse_history_train.txt',encoding='gb2312',header=None,names=['用户标识','浏览时间','浏览行为数据','浏览子行为编号'])\n",
    "browse_test=pd.read_csv('../data/test/browse_history_test.txt',encoding='gb2312',header=None,names=['用户标识','浏览时间','浏览行为数据','浏览子行为编号'])\n",
    "browse=pd.concat([browse_train,browse_test],axis=0)\n",
    "\n",
    "browse['浏览日期'] = browse['浏览时间'].apply(lambda x :time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(x)))\n",
    "browse['浏览日期'] = pd.to_datetime(browse['浏览日期'])\n",
    "browse['month'] = browse['浏览日期'].apply(lambda x :x.strftime('%m'))\n",
    "browse['week']= browse['浏览日期'].dt.dayofweek ##输出这一天是周中的第几天，Monday=0, Sunday=6\n",
    "browse['day'] = browse['浏览日期'].apply(lambda x :x.strftime('%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=list(browse['浏览子行为编号'].unique())\n",
    "B=list(browse['浏览行为数据'].unique())\n",
    "Cm=list(list(range(1,13,1)))\n",
    "Cw=list(range(0,7,1))\n",
    "Cd=list(range(1,32,1))\n",
    "\n",
    "#浏览子行为编号的比重\n",
    "Pa=[1644330,913855,1132344,1468039,1742281,1975832,1376926,2688287,3387346, 4824424,4198328]\n",
    "Pa=np.array(Pa)\n",
    "Pa=Pa/sum(Pa)\n",
    "\n",
    "#浏览行为数据的比重\n",
    "Pb=Counter(browse['浏览行为数据'])\n",
    "a=sorted(Pb.items(),key=lambda x:x[0],reverse=False)\n",
    "Pb=[]\n",
    "for i in range(216):\n",
    "    Pb.append(a[i][1])\n",
    "Pb=np.array(Pb)\n",
    "Pb=Pb/sum(Pb)\n",
    "\n",
    "#month 的概率比重\n",
    "Pm=Counter(browse['month'])\n",
    "a=sorted(Pm.items(),key=lambda x:x[0],reverse=False)\n",
    "Pm=[]\n",
    "for i in range(12):\n",
    "    Pm.append(a[i][1])\n",
    "Pm=np.array(Pm)\n",
    "Pm=Pm/sum(Pm)\n",
    "\n",
    "def single_id(ID,N,n1,n2,n3,n4,n5):\n",
    "    \n",
    "    #生成单个id的特征总集\n",
    "    A1=np.random.choice(A,n1,replace=False,p=Pa)\n",
    "    B1=np.random.choice(B,n2,replace=False,p=Pb)\n",
    "    C1=np.random.choice(Cm,n3,replace=False,p=Pm)\n",
    "    C2=np.random.choice(Cw,n4,replace=False)\n",
    "    C3=np.random.choice(Cd,n5,replace=False)\n",
    "    \n",
    "    #二重概率抽样的概率\n",
    "    Pa1 = Pa[A1-1]\n",
    "    Pa1=Pa1 /sum(Pa1)\n",
    "    Pb1 = Pb[B1-1]\n",
    "    Pb1=Pb1 /sum(Pb1)\n",
    "    Pm1 = Pm[C1-1]\n",
    "    Pm1=Pm1 /sum(Pm1)\n",
    "    \n",
    "    #生成各特征取值list\n",
    "    子行为编号=np.random.choice(A1,N,replace=True,p=Pa1)\n",
    "    浏览行为数据=np.random.choice(B1,N,replace=True,p=Pb1)\n",
    "    month=np.random.choice(C1,N,replace=True,p=Pm1)\n",
    "    week=np.random.choice(C2,N,replace=True)\n",
    "    day=np.random.choice(C3,N,replace=True)\n",
    "\n",
    "    c={'用户标识':ID,'浏览子行为编号':子行为编号,'浏览行为数据':浏览行为数据,'month':month,'week':week,'day':day}\n",
    "    c=pd.DataFrame(c)\n",
    "    return c\n",
    "\n",
    "def  get_browse(d):\n",
    "    #提取每个id的关键信息\n",
    "    ID = d['用户标识']\n",
    "    N = d['浏览次数']\n",
    "    n1 = d['浏览子行为编号种类']\n",
    "    n2 = d['浏览行为数据种类']\n",
    "    n3 = d['month种类']\n",
    "    n4 = d['week种类']\n",
    "    n5 = d['day种类']\n",
    "    c=single_id(ID,N,n1,n2,n3,n4,n5)\n",
    "    print(c)\n",
    "    #c=pd.concat([smo_browse,c],axis=0)\n",
    "    #print(c)\n",
    "    return c\n",
    "    \n",
    "smo_browse=pd.DataFrame(columns=('用户标识','浏览子行为编号','浏览行为数据','month','week','day'))\n",
    "\n",
    "if __name__ == '__main__':   \n",
    "    smo_browse= bf.apply(get_browse , axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合并apply出来的单个id 的浏览记录\n",
    "sss=pd.DataFrame(smo_browse)\n",
    "smo_browse1=pd.DataFrame(columns=('用户标识','浏览子行为编号','浏览行为数据','month','week','day'))\n",
    "for i in range(len(bf)):\n",
    "    browse_id=pd.DataFrame(sss.iloc[i,0])\n",
    "    a=i\n",
    "    #print(a)\n",
    "    smo_browse1=pd.concat([smo_browse1,browse_id],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成新的银行流水记录\n",
    "## 具体步骤\n",
    "- 定义各关键信息\n",
    "       n1：收入的次数\n",
    "       V1：收入总计\n",
    "       n2：工资笔数\n",
    "       v2：工资总计\n",
    "       n3：支出笔数\n",
    "       V3：支出总计\n",
    "       \n",
    "-  生成工资表： n2工资笔数、v2工资总计\n",
    "   1. 生成时间戳\n",
    "     判断n2<=18？   \n",
    "          是，则生成n2个月的工资时间戳（每月同一时间）\n",
    "          否，则先生成18个月的工资时间戳，多于18的工资时间戳随机生成\n",
    "   2. 生成工资记录\n",
    "     生成n2个随机数（这里取[10,20]），调整其和为v2\n",
    "   3. 交易类型：0；工资标记：1\n",
    "   \n",
    "- 生成收入表：n1收入的次数，V1收入总计\n",
    "   1. 在时间范围内随机生成时间戳（n1-n2）个\n",
    "   2. 交易金额：生成（n1-n2）个随机数（这里取[10,20]），调整其和为（v1-v2）\n",
    "   3. 交易类型：0；工资标记：0\n",
    "   \n",
    "- 生成支出表：n3支出笔数，V3支出总计\n",
    "   1. 在时间范围内随机生成时间戳n3个\n",
    "   2. 交易金额：生成n3个随机数（这里取[10,20]），调整其和为v3\n",
    "   3. 交易类型：1；工资标记：0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=bank_key_features\n",
    "#-----------工资表---------------\n",
    "def salary(ID,n2,v2):\n",
    "    \n",
    "    工资表=pd.DataFrame(columns=('用户标识','流水时间','交易类型','交易金额','工资收入标记'))\n",
    "    #生成时间戳\n",
    "    if np.isnan(n2):\n",
    "        工资表=工资表\n",
    "    else:\n",
    "        n2=int(n2)\n",
    "        i=random.randint(0,31)\n",
    "        end_time=5928939087-i*60*60*24  #工资时间都是出现在当天的7:31分，为保持一致随机生成最后一月随机一天的7:31作为工资每月发放时间点\n",
    "        \n",
    "        if n2<=18:   #原有样本时间跨度差不多在18个月左右，于是进行判断\n",
    "            salary_time=[]\n",
    "            for i in range(n2):\n",
    "                salary_time.append(end_time-30*24*60*60*i)\n",
    "        else:\n",
    "            salary_time1=[]\n",
    "            for i in range(18):\n",
    "                salary_time1.append(end_time-30*24*60*60*i)\n",
    "            n=n2-18      #对于大于18个月的ID，多于的时间点就随机生成\n",
    "            salary_time2=[random.randint(5879518000,5928983000) for _ in range(n)]#random.randomint(5879518000,5928983000,n)\n",
    "            salary_time=salary_time1+salary_time2\n",
    "        \n",
    "        #生成工资金额序列\n",
    "        salary=np.random.randint(10,20,n2)\n",
    "        ratio=v2/sum(salary)\n",
    "        salary=list(salary*ratio)\n",
    "\n",
    "        工资表={'用户标识':ID,'流水时间':salary_time,'交易类型':0,'交易金额':salary,'工资收入标记':1}\n",
    "        工资表=pd.DataFrame(工资表)\n",
    "    return 工资表\n",
    "#-------------收入表- -----------\n",
    "def income(ID,n1,v1,n2,v2):\n",
    "    收入表=pd.DataFrame(columns=('用户标识','流水时间','交易类型','交易金额','工资收入标记'))\n",
    "    n=n1-n2\n",
    "    if np.isnan(n):\n",
    "        收入表=收入表\n",
    "    else:\n",
    "        if n==0:\n",
    "            收入表=收入表\n",
    "        else:\n",
    "            n=int(n)\n",
    "            income_time=[random.randint(5879518000,5928983000) for _ in range(n)] #random.randomint(5879518000,5928983000,n)        \n",
    "           #生成工资金额序列\n",
    "            income=np.random.randint(10,20,n)\n",
    "            ratio=(v1-v2)/sum(income)\n",
    "            income=list(income*ratio)\n",
    "\n",
    "            收入表={'用户标识':ID,'流水时间':income_time,'交易类型':0,'交易金额':income,'工资收入标记':0}\n",
    "            收入表=pd.DataFrame(收入表)\n",
    "    return 收入表\n",
    "#-------------支出表---------------\n",
    "def outcome(ID,n3,v3):\n",
    "    支出表=pd.DataFrame(columns=('用户标识','流水时间','交易类型','交易金额','工资收入标记'))\n",
    "\n",
    "    if np.isnan(n3):\n",
    "        支出表=支出表\n",
    "    else:\n",
    "        n3=int(n3)\n",
    "        outcome_time=[random.randint(5879518000,5928983000) for _ in range(n3)]  #random.randomint(5879518000,5928983000,n)      \n",
    "    #生成工资金额序列\n",
    "        outcome=np.random.randint(10,20,n3)\n",
    "        ratio=v3/sum(outcome)\n",
    "        outcome=list(outcome*ratio)\n",
    "\n",
    "        支出表={'用户标识':ID,'流水时间':outcome_time,'交易类型':1,'交易金额':outcome,'工资收入标记':0}\n",
    "        支出表=pd.DataFrame(支出表)\n",
    "        \n",
    "    return 支出表\n",
    "\n",
    "def get_feature(k):\n",
    " #n1收入的次数，V1收入总计；n2工资笔数，v2工资总计；n3支出笔数，V3支出总计\n",
    "    ID=k['用户标识']\n",
    "    n1=k['用户收入笔数']\n",
    "    v1=k['用户收入总计']\n",
    "    n2=k['用户工资笔数']\n",
    "    v2=k['用户工资总计']\n",
    "    n3=k['用户支出笔数']\n",
    "    v3=k['用户支出总计']\n",
    "    \n",
    "    工资表 = salary(ID,n2,v2)\n",
    "    收入表 = income(ID,n1,v1,n2,v2)\n",
    "    支出表 = outcome(ID,n3,v3)\n",
    "    \n",
    "    bank_id = pd.concat([工资表,收入表],axis=0)\n",
    "    bank_id = pd.concat([bank_id,支出表],axis=0)\n",
    "    bank_id= bank_id.sort_values(by='流水时间')\n",
    "    \n",
    "    return bank_id\n",
    "\n",
    "if __name__ == '__main__':   \n",
    "    smo_bank= k.apply(get_feature , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将apply出来的表进行合并\n",
    "smo_bank= pd.DataFrame(smo_bank)\n",
    "smo_bank1=pd.DataFrame(columns=('用户标识','流水时间','交易类型','交易金额','工资收入标记'))\n",
    "\n",
    "for i in range(len(k)):\n",
    "    bank_id=pd.DataFrame(smo_bank.iloc[i,0])\n",
    "    #print(i)\n",
    "    smo_bank1=pd.concat([smo_bank1,bank_id],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成新的用户基本信息表\n",
    "## 具体步骤\n",
    "用户基本信息表中包含六个字段：用户标识、用户性别、用户职业、用户教育程度、用户婚姻状态、用户户口类型\n",
    "- 生成新正样本的用户基本信息表\n",
    "  1. 从原有正样本用户基本信息表中，分别从除id的5个基本特征构成的5个集合中随机抽取8000条，构成最终新正样本的用户基本信息。\n",
    "  2. 提取smo_overdue中新正样本的id，从而生成新正样本中用户基本信息的id\n",
    "- 生成新负样本的用户基本信息表：\n",
    "  1. 从原有负样本用户基本信息表中，分别从除id的5个基本特征构成的5个集合中随机抽取12000条，构成最终新正样本的用户基本信息。\n",
    "  2. 提取smo_overdue中新负样本的id，从而生成新负样本中用户基本信息的id\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "读取数据、并划分正负样本分别对应的用户基本信息表\n",
    "'''\n",
    "smo_overdue=pd.read_csv('smo_sample/smo_overdue.csv',encoding='gb2312')\n",
    "\n",
    "user=pd.read_csv(\"../data/train/user_info_train.txt\",header=None,names=['用户标识','用户性别','用户职业',\n",
    "                    '用户教育程度','用户婚姻状态','用户户口类型'])\n",
    "user_test=pd.read_csv(\"../data/test/user_info_test.txt\",header=None,names=['用户标识','用户性别','用户职业',\n",
    "                    '用户教育程度','用户婚姻状态','用户户口类型'])\n",
    "user=pd.concat([user,user_test],axis=0)\n",
    "\n",
    "overdue=pd.read_csv(\"../Data/train/overdue_train.txt\",header=None,names=['用户标识','样本标签'])\n",
    "overdue_test=pd.read_csv(\"../Data/test/overdue_test.csv\")\n",
    "overdue_test=overdue_test.rename(columns={'userid':'用户标识','probability':'样本标签'})\n",
    "overdue=pd.concat([overdue,overdue_test],axis=0)\n",
    "overdue = overdue.reset_index(drop= True)\n",
    "user = pd.merge(user,overdue,on='用户标识',how='outer')\n",
    "\n",
    "smo_overdue_1=smo_overdue[smo_overdue['样本标签']==1]\n",
    "smo_overdue_0=smo_overdue[smo_overdue['样本标签']==0]\n",
    "\n",
    "user_1=user[user['样本标签']==1]\n",
    "user_0=user[user['样本标签']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------对于label=0  生成user基本信息-------------------\n",
    "#从原负样本的各个特征列中 随机抽取12000条数据构成新id负样本的特征\n",
    "\n",
    "data= user_0\n",
    "ID=smo_overdue_0['用户标识']\n",
    "用户性别 = np.random.choice(data['用户性别'], 12000)\n",
    "用户职业 = np.random.choice(data['用户职业'], 12000)\n",
    "用户教育程度 = np.random.choice(data['用户教育程度'], 12000)\n",
    "用户婚姻状态 = np.random.choice(data['用户婚姻状态'], 12000)\n",
    "用户户口类型 = np.random.choice(data['用户户口类型'], 12000)\n",
    "\n",
    "smo_user_0={'用户标识':ID,'用户性别':用户性别,'用户职业':用户职业,'用户教育程度':用户教育程度,'用户婚姻状态':用户婚姻状态,'用户户口类型':用户户口类型}\n",
    "smo_user_0=pd.DataFrame(smo_user_0)\n",
    "\n",
    "#--------------------对于label=1  生成user基本信息-------------------\n",
    "#从原正样本的各个特征列中 随机抽取8000条数据构成新id正样本的特征\n",
    "data= user_1\n",
    "ID=smo_overdue_1['用户标识']\n",
    "用户性别 = np.random.choice(data['用户性别'], 8000)\n",
    "用户职业 = np.random.choice(data['用户职业'], 8000)\n",
    "用户教育程度 = np.random.choice(data['用户教育程度'], 8000)\n",
    "用户婚姻状态 = np.random.choice(data['用户婚姻状态'], 8000)\n",
    "用户户口类型 = np.random.choice(data['用户户口类型'], 8000)\n",
    "\n",
    "smo_user_1={'用户标识':ID,'用户性别':用户性别,'用户职业':用户职业,'用户教育程度':用户教育程度,'用户婚姻状态':用户婚姻状态,'用户户口类型':用户户口类型}\n",
    "smo_user_1=pd.DataFrame(smo_user_1)\n",
    "\n",
    "smo_user=pd.concat([smo_user_0,smo_user_1],axis=0)\n",
    "smo_user=smo_user.sort_values(by='用户标识')\n",
    "#smo_user.to_csv('smo_sample/smo_user.csv',encoding='gb2312',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理信用卡账单记录表\n",
    " 处理信用卡账单数据  \n",
    "- 问题：  \n",
    "  1. 时间错乱\n",
    "  2. 数字太乱  \n",
    "  3. 可能出现账单的断裂\n",
    "- 目标：  \n",
    "  1. 归序时间  \n",
    "  2. 优化数字的显示方式  \n",
    "  3. 拼接账单链\n",
    "- 步骤：\n",
    "  1. 排序-为每个用户每张信用卡的账单  \n",
    "  2. 完善账单链，并补充时间，间隔先设置为30天\n",
    "  3. 更改金额数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# 变量定义\n",
    "N = 20000           # 定义新生成样本的数量\n",
    "LimitBanks = 4      # 每个人最多有4个银行卡\n",
    "indBenQi = 6        # 本期账单余额所在列\n",
    "indShangQi = 3      # 上期账单金额所在列\n",
    "indShangQiHuan = 4  # 上期还款金额所在列\n",
    "indEdu = 5          # 信用卡额度所在列\n",
    "indTime = 2         # 时间戳所在的列\n",
    "pAddrec = 0.8       # 加入新纪录作为粘合两条断裂链的概率\n",
    "newidStart = 69495  # 新样本的编号，从这个数字开始"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "- 有重复值。$\\color{red}{删除}$重复值\n",
    "- 不同银行简单统计。\n",
    "  1. 因为数据来自不同银行，会发现一些银行的数据比较诡异，故需查看。  \n",
    "    bankid = 1，3100条记录，缺失值非常多    \n",
    "    bankid = 2，13.5万条记录，相对质量较高  \n",
    "    bankid = 3，22.1万条记录，基本没有上期账单金额和还款金额  \n",
    "    bankid = 4，26.5万条记录  \n",
    "    bankid = 510014和510044，有循环利息，但数据量较少\n",
    "  2. $\\color{red}{删除}$部分银行的记录。  \n",
    "    编号为1、12，以及所有大于50000的银行id，数量都较少。\n",
    "- 需直接$\\color{red}{删除}$的字段\n",
    "  1. 消费笔数：经常出现消费笔数为0，但账单余额不为0的情况。  \n",
    "  2. 可用余额：出现数量非常少，在某个银行id下会较多。但此数字非常奇怪。  \n",
    "  3. 调整金额，循环利息，预借现金额度：基本上都是空值，仅在少量小众银行下有值。   \n",
    "  4. 本期账单金额：数值非常奇怪，感觉跟其余的字段完全没有关系。  \n",
    "  5. 本期账单最低还款额：基本没有什么用处。  \n",
    "- 需判断后处理的记录\n",
    "  1. 信用卡额度：有些用户会有较大波动，估计是数据合并时出现错误。需检查波动情况，然后删除此用户此银行的所有记录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  第1步，读入数据，删除无用字段，并删除重复值\n",
    "'''\n",
    "datapath = '../data/'\n",
    "train_credit = pd.read_csv(datapath + 'train/bill_detail_train.txt', header = None)\n",
    "test_credit = pd.read_csv(datapath + 'test/bill_detail_test.txt', header = None)\n",
    "train_credit = pd.concat([train_credit,test_credit],axis = 0)\n",
    "train_credit.columns = ['用户id','账单时间戳','银行id','上期账单金额','上期还款金额','信用卡额度','本期账单余额',  \n",
    "                     '本期账单最低还款额','消费笔数','本期账单金额','调整金额','循环利息','可用余额',  \n",
    "                     '预借现金额度','还款状态']\n",
    "print('原始数据总规模为：', train_credit.shape)\n",
    "remvVars = ['消费笔数','可用余额','调整金额','循环利息','预借现金额度','本期账单金额', '本期账单最低还款额']\n",
    "train_credit.drop(remvVars, axis=1, inplace=True)\n",
    "train_credit.drop_duplicates(inplace=True)\n",
    "print('删除无用字段和重复值之后的数据总规模为：', train_credit.shape)\n",
    "train_credit.drop\n",
    "train_credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  第2步，删除指定银行的数据\n",
    "'''\n",
    "remvBankid = [1,3,12,510014,510016,510017,510022,510024,510025,510026,510027,510033,510037,510044,510050,510053,510057]\n",
    "train_credit = train_credit.set_index(['银行id'])\n",
    "train_credit.drop(remvBankid,inplace=True)\n",
    "train_credit.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  第3步，删除信用卡额度变化太快的字段\n",
    "  \n",
    "  方法：取出每一对（用户id，银行id）对应的记录，然后判断其众数，若众数数量不超过\n",
    "  min(6,总记录数量的一半)，则不保留此数据\n",
    "'''\n",
    "# 新建一个df，存放被保留的数据\n",
    "temp_df = pd.DataFrame()\n",
    "# 取出所有用户id\n",
    "user_lst = list(set(train_credit['用户id'].tolist()))\n",
    "i = 1\n",
    "for usr in user_lst:\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print('已完成处理%d个用户...'%i)\n",
    "    # 取出用户usr的所有记录\n",
    "    usr_df = train_credit[train_credit['用户id']==usr]\n",
    "    # 取出用户usr的所有银行id\n",
    "    bank_lst = list(set(usr_df['银行id'].tolist()))\n",
    "    for bank in bank_lst:\n",
    "        # 取出用户usr&银行bank的所有记录\n",
    "        usr_bank_df = usr_df[usr_df['银行id']==bank]\n",
    "        if usr_bank_df.shape[0] < 3:\n",
    "            temp_df = pd.concat([temp_df,usr_bank_df], axis=0)\n",
    "        else:\n",
    "            # 求得“信用卡额度”的众数出现的次数\n",
    "            limit_count = usr_df['信用卡额度'].value_counts()\n",
    "            limit_mostFreqCount = list(limit_count)[0]\n",
    "            if limit_mostFreqCount < min(6,int(usr_df['信用卡额度'].shape[0]/2)):\n",
    "                # 跳过这个usr_bank_df\n",
    "                pass\n",
    "            else:\n",
    "                temp_df = pd.concat([temp_df,usr_bank_df], axis=0)\n",
    "        \n",
    "print('删除异常信用卡额度之后的数据总规模为：', temp_df.shape)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  最后，把处理好的数据写入文件，备用\n",
    "''' \n",
    "temp_df.to_csv('Billdata_clean_20190817.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 排序-单个用户单个银行\n",
    "- 方法：\n",
    "  1. 以原数据的时间作为基本排序\n",
    "  2. 根据“上期账单账单金额”与“本期账单金额”的对应关系，优化时间序列\n",
    "  3. 若存在断链的情况，则找出所有可以连起来的链；再做进一步的判断\n",
    "- 处理流程：  \n",
    "  请见同文件下文件名：农业银行数据-信用卡账单处理流程图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 读入新数据\n",
    "bill_df = pd.read_csv('Billdata_clean_20190817.csv')\n",
    "bill_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 定义排序函数\n",
    "def sortBillList(df_usr_bank):\n",
    "    # 由于dataframe类型，不便于重复删除指定行，且控制好指针，故转为二维数组\n",
    "    arr = df_usr_bank.sort_values(by='账单时间戳').values\n",
    "        \n",
    "    # bill链可能会出现断裂，此时会找到所有连续的链，存放于resL。\n",
    "    resL = []             # resL定义为一个三维数组\n",
    "    while True:\n",
    "        if len(arr) == 0:\n",
    "            return resL\n",
    "        elif len(arr) == 1:\n",
    "            L = [list(arr[0])]\n",
    "            resL += [L,]\n",
    "            return resL\n",
    "        else:\n",
    "            L = []\n",
    "            L = L + [list(arr[0]),]   #在L中加入arr中的第一条 然后进行判断\n",
    "            arr = np.delete(arr,0,axis=0)\n",
    "            i = 0\n",
    "            \n",
    "            while i < len(arr):\n",
    "                if arr[i][indShangQi] == L[len(L)-1][indBenQi]:   \n",
    "                    L = L + [list(arr[i]),]\n",
    "                    arr = np.delete(arr,i,axis=0)\n",
    "                    i = 0\n",
    "                elif arr[i][indBenQi] == L[0][indShangQi]:   \n",
    "                    L = [list(arr[i]),] + L\n",
    "                    arr = np.delete(arr,i,axis=0)\n",
    "                    i = 0\n",
    "                else:\n",
    "                    i += 1\n",
    "            # 然后判断df是否为空\n",
    "            resL = resL + [L,]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出所有用户id； 建议分几批来运行，速度会快很多。每次生成的数据，保存成npy即可。\n",
    "userSet = list(set(bill_df['用户id'].tolist()))\n",
    "\n",
    "allSortedList = []\n",
    "\n",
    "# 遍历每一位用户\n",
    "i = 1\n",
    "for usr in userSet:\n",
    "    if i % 1000 == 0:\n",
    "        print('已处理%d个用户...'%i)\n",
    "    i += 1\n",
    "    df_usr = bill_df.loc[bill_df['用户id'] == usr]\n",
    "    # 遍历此用户的每一个银行id\n",
    "    bankSet = set(df_usr['银行id'].tolist())\n",
    "    for bank in bankSet:\n",
    "        df_usr_bank = df_usr.loc[df_usr['银行id'] == bank]\n",
    "        # 调用排序算法,返回生成该“用户&银行”的所有list，存入allSortedList\n",
    "        allSortedList = allSortedList + [sortBillList(df_usr_bank)]\n",
    "    \n",
    "\n",
    "# 将数据保存\n",
    "np.save('tempBillChain.npy',allSortedList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并BillChains\n",
    "- 背景  \n",
    "  对于当前的数据，对用户u银行i的所有信用卡账单，断裂非常严重，需要补成链状。  \n",
    "- 合并的顺序  \n",
    "  以信用卡额度为标准，小额度的尽可能放前面。\n",
    "- 方法  \n",
    "  1. 按较高的概率，添加一条记录，把两条断裂的链粘合起来\n",
    "  2. 按较小的概率，直接把两条链放在一起，就当作是记录缺失了  \n",
    "  \n",
    "  具体的方案，可以看当前目录下的流程图，合并Billchains.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入排好顺序的BillChain\n",
    "allSortedList = np.load('tempBillChain.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得每一个连续链的第一个非0信用卡额度值\n",
    "def getValidCreditLimit(lst2d, ind):\n",
    "    res = 0\n",
    "    for templst in lst2d:\n",
    "        if templst[ind] > res:\n",
    "            res = templst[ind]\n",
    "            break\n",
    "    return res\n",
    "\n",
    "# 开始合并\n",
    "mergedChains = []\n",
    "iout = 1\n",
    "for usr_bank_list in allSortedList:\n",
    "    if iout % 1000 == 0:\n",
    "        print('已处理%d个用户...'%iout)\n",
    "    iout += 1\n",
    "    \n",
    "    resL = usr_bank_list[0]\n",
    "    # 获取当前resL中首个大于0的额度\n",
    "    begCreditLimit = getValidCreditLimit(resL, indEdu)\n",
    "            \n",
    "    for i in range(1,len(usr_bank_list)):\n",
    "        # 获取当前usr_bank_list[i]记录中，第一个不为0的额度\n",
    "        thisCreditLimit = getValidCreditLimit(usr_bank_list[i], indEdu)\n",
    "        \n",
    "        if thisCreditLimit < begCreditLimit:           \n",
    "            # 把第i条记录加在resL“头部”\n",
    "            if random.random() < pAddrec:\n",
    "                # 新增记录，链接resL[0]和usr_bank_list[i]\n",
    "                newrecord = usr_bank_list[i][len(usr_bank_list[i])-1][:]\n",
    "                # 新增记录的上期金额 = usr_bank_list[i][end][本期]\n",
    "                newrecord[indShangQi] = usr_bank_list[i][len(usr_bank_list[i])-1][indBenQi]   \n",
    "                # 新增记录的本期余额 = resL[0][上期]\n",
    "                newrecord[indBenQi] = resL[0][indShangQi]                 \n",
    "                # 新增记录的上期还款金额，在上期金额上，进行浮动，[-0.2，0.2]\n",
    "                newrecord[indShangQiHuan] = newrecord[indShangQi] + (random.random()-0.5)/2\n",
    "                resL = [newrecord] + resL\n",
    "            resL = usr_bank_list[i] + resL\n",
    "        else:\n",
    "            # 把第i条记录加在resL“尾部”\n",
    "            if random.random() < pAddrec:\n",
    "                # 新增记录，链接resL[end]和usr_bank_list[i]\n",
    "                newrecord = resL[len(resL)-1][:]\n",
    "                # 新增记录的上期金额 = resL[end][本期]\n",
    "                newrecord[indShangQi] = resL[len(resL)-1][indBenQi] \n",
    "                # 新增记录的本期余额 = usr_bank_list[i][0][上期]\n",
    "                newrecord[indBenQi] = usr_bank_list[i][0][indShangQi]  \n",
    "                # 新增记录的上期还款金额，在上期金额上，进行浮动，[-0.2，0.2]\n",
    "                newrecord[indShangQiHuan] = newrecord[indShangQi] + (random.random()-0.5)/2\n",
    "                resL = resL + [newrecord]\n",
    "            resL = resL + usr_bank_list[i]\n",
    "            begCreditLimit = thisCreditLimit\n",
    "    \n",
    "    mergedChains = mergedChains + [resL,]\n",
    "\n",
    "# 把得到的结果保存下来，原始数据的记录\n",
    "np.save('initialUserBillChainP'+str(pAddrec)+'.npy',mergedChains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成新样本\n",
    "- 目的与原则\n",
    "  1. 补充新的样本数据\n",
    "  2. 需要区分正负样本，12000个负样本，8000个正样本\n",
    "- 方法\n",
    "  1. 为每一个用户，安排1~4个银行\n",
    "  2. 对于新的正样本用户，仅选择正样本用户的信用卡账单情况；负样本用户同样仅对应负样本\n",
    "  3. 在原有记录上，仅删除样本数据  \n",
    "  \n",
    "  具体的删除样本方案，可以看当前目录下的流程图，生成新样本.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先读入数据\n",
    "initialBillChains = np.load('initialUserBillChainP'+str(pAddrec)+'.npy')\n",
    "# 根据标签数据 'overdue_train.txt'，将initialBillChains分成两部分\n",
    "labels = pd.read_csv('../data/train/overdue_train.txt',header=None)\n",
    "labels.columns = ['用户id','label']\n",
    "\n",
    "iniBCpos, iniBCneg = [],[]\n",
    "ii = 1\n",
    "for lst in initialBillChains:\n",
    "    if ii % 1000 == 0:\n",
    "        print('已完成%d条，共%d条...'%(ii,len(initialBillChains)))\n",
    "    ii += 1\n",
    "    usrid = lst[0][1]\n",
    "    try:\n",
    "        if labels[labels['用户id']==usrid]['label'].tolist()[0] == 1:\n",
    "            iniBCpos = iniBCpos + [lst]\n",
    "        else:\n",
    "            iniBCneg = iniBCneg + [lst]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateSamples(iniBC,idStart,Nsample):\n",
    "    newUserBC = []\n",
    "    for i in range(Nsample):\n",
    "        if (i+1)%500 == 0:\n",
    "            print('已新建%d个用户...'%i)\n",
    "        r = np.random.randint(LimitBanks) + 1\n",
    "        newid = idStart + i\n",
    "        banks = []\n",
    "        for _ in range(r):\n",
    "            # 随机取出一条记录，应是一个二维数组\n",
    "            tempind =  np.random.randint(len(iniBC))\n",
    "            thisChain = copy.deepcopy( iniBC[tempind] )\n",
    "            # 取出这条记录的bankid\n",
    "            bankid = thisChain[0][0]\n",
    "            if bankid in banks:\n",
    "                continue\n",
    "            # 开始改造这条记录\n",
    "            banks.append(bankid)\n",
    "\n",
    "            ####### 改造1：删除记录\n",
    "            if np.random.random() < 0.5:\n",
    "                # 只删除头或尾\n",
    "                x = min(7,int((len(thisChain)-1)/3) )\n",
    "                xhead = int(x/2)\n",
    "                xtail = x-xhead\n",
    "                thisChain = np.delete(thisChain,range(xhead),axis=0)\n",
    "                thisChain = np.delete(thisChain,range(len(thisChain)-xtail,len(thisChain)),axis=0)\n",
    "            else:\n",
    "                # 混合删除\n",
    "                a = min(7,int((len(thisChain)-1)/3) )\n",
    "                y = min(3,a)\n",
    "                if a>3:\n",
    "                    x = a-3\n",
    "                    xhead = int(x/2)\n",
    "                    xtail = x-xhead\n",
    "                    thisChain = np.delete(thisChain,range(xhead),axis=0)\n",
    "                    thisChain = np.delete(thisChain,range(len(thisChain)-xtail,len(thisChain)),axis=0)\n",
    "                # 删除y个中间值\n",
    "                remvInds = np.random.randint(0,len(thisChain),y)\n",
    "                thisChain = np.delete(thisChain,remvInds,axis=0)\n",
    "\n",
    "            ####### 改造2：替换userid\n",
    "            thisChain[:,1] = newid\n",
    "\n",
    "            ####### 改造3：上期金额、本期余额、信用卡额度，统一添加一个随机数\n",
    "            ################### 但原来为0的，不能加\n",
    "            temprand = (np.random.random() - 0.5)/2\n",
    "            thisChain[:,indBenQi] = thisChain[:,indBenQi] + temprand\n",
    "            thisChain[:,indShangQi] = thisChain[:,indShangQi] + temprand\n",
    "            thisChain[:,indEdu] = thisChain[:,indEdu] + temprand\n",
    "\n",
    "            ####### 改造4：上期还款金额，各自改一个小小的随机数\n",
    "            thisChain[:,indShangQiHuan] = thisChain[:,indShangQiHuan] + temprand/10\n",
    "            \n",
    "            thisChain[(thisChain < 0.5) & (thisChain>-0.5)] = 0\n",
    "            \n",
    "            newUserBC = newUserBC + [thisChain,]\n",
    "    return newUserBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newBCneg = GenerateSamples(iniBCneg,newidStart,12000)\n",
    "newBCpos = GenerateSamples(iniBCpos,newidStart+12000,8000)\n",
    "np.save('newUserBCneg.npy',newBCneg)\n",
    "np.save('newUserBCpos.npy',newBCpos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 样本进一步加工\n",
    "- 方法\n",
    "  1. 以较大概率，0.6，将一些负值置为0  \n",
    "  2. 若时间戳为0，则以0.5的概率将此条记录删除  \n",
    "  3. 若时间戳不为0，则在原来时间上做一些修改，找到第一个不为0的时间，往后看每一条记录  \n",
    "     3.1 若与前一条连续，则加(29.8~31.2)天的偏移。  \n",
    "     3.2 如不连续，则加(29.8~31.2)天的偏移。  \n",
    "     注：当前时间戳，单位为秒，因此需要 $随机数*24*3600$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Process(billChains):\n",
    "    thisBC = []\n",
    "    for lst in billChains:\n",
    "        # 遍历此记录\n",
    "        lst = np.array(lst)\n",
    "        i = 0\n",
    "        while i < len(lst):\n",
    "            if lst[i][indTime] == 0:\n",
    "                if np.random.random() < 0.5:\n",
    "                    lst = np.delete(lst, i, axis=0)\n",
    "                    i -= 1\n",
    "                elif np.random.random() < 0.6:\n",
    "                    # 将负值置为0\n",
    "                    lst[lst < 0] = 0\n",
    "            else:\n",
    "                if np.random.random() < 0.6:\n",
    "                    # 将负值置为0\n",
    "                    lst[lst < 0] = 0\n",
    "                try:\n",
    "                    if lst[i][indBenQi] == lst[i+1][indShangQi]:\n",
    "                        timelag = int((np.random.random()*(31.2-29.8) + 29.8) * 24 * 3600)\n",
    "                        lst[i+1][indTime] = lst[i][indTime] + timelag\n",
    "                    else:\n",
    "                        timelag = int((np.random.random()*(31.2-29.8) + 29.8) * 24 * 3600 * np.random.randint(2,4))\n",
    "                        lst[i+1][indTime] = lst[i][indTime] + timelag\n",
    "                except:\n",
    "                    pass\n",
    "            i += 1\n",
    "        thisBC = thisBC + [lst]\n",
    "    return thisBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理newUserBCpos\n",
    "newBCpos = np.load('newUserBCpos.npy')\n",
    "newBCpos1 = Process(newBCpos)\n",
    "# 处理newUserBCneg\n",
    "newBCneg = np.load('newUserBCneg.npy')\n",
    "newBCneg1 = Process(newBCneg)\n",
    "# 处理iniBC\n",
    "iniBC = np.load('initialUserBillChainP0.8.npy')\n",
    "iniBC1 = Process(iniBC)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将array还原成dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "def arrayToDF(arr):\n",
    "    res = []\n",
    "    for lst in arr:\n",
    "        res = res + list(lst)\n",
    "    res_df = pd.DataFrame(res)\n",
    "    res_df.columns = ['银行id','用户id','账单时间戳','上期账单金额','上期还款金额','信用卡额度','本期账单余额','还款状态']\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newBCpos_df = arrayToDF(newBCpos1)\n",
    "newBCpos_df.to_csv('newBill_pos.csv', index = 0)\n",
    "\n",
    "newBCneg_df = arrayToDF(newBCneg1)\n",
    "newBCneg_df.to_csv('newBill_neg.csv', index = 0)\n",
    "\n",
    "## 由于过摸较大要分开写，运行才会比较快，比如下面的可替换代码\n",
    "iniBC_df = arrayToDF(iniBC1)\n",
    "iniBC_df.to_csv('Bill.csv', index = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可替换的代码\n",
    "iniBC1_1 = iniBC1[0:30000]\n",
    "iniBC_df1 = arrayToDF(iniBC1_1)\n",
    "iniBC1_2 = iniBC1[30000:60000]\n",
    "iniBC_df2 = arrayToDF(iniBC1_2)\n",
    "#诸如此类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "364.25px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
